{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.mllib.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"Office_Products_5.json\"\n",
    "APP_NAME = \"Amazon Sentiment Analysis\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "RANDOM_SEED = 141107\n",
    "TRAINING_DATA_RATIO = 0.8\n",
    "\n",
    "RF_NUM_TREES = 10\n",
    "RF_MAX_DEPTH = 4\n",
    "RF_NUM_BINS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
    "df = sc.read.options(inferschema = \"true\").json(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------------+-----------+--------------+-------------------+--------------------+--------------+\n",
      "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|       reviewerName|             summary|unixReviewTime|\n",
      "+----------+-------+-------+--------------------+-----------+--------------+-------------------+--------------------+--------------+\n",
      "|B00000JBLH| [3, 4]|    5.0|I bought my first...| 09 3, 2004|A32T2H8150OJLU|                ARH|A solid performer...|    1094169600|\n",
      "|B00000JBLH| [7, 9]|    5.0|WHY THIS BELATED ...|12 15, 2007|A3MAFS04ZABRGO|   Let it Be \"Alan\"|Price of GOLD is ...|    1197676800|\n",
      "|B00000JBLH| [3, 3]|    2.0|I have an HP 48GX...| 01 1, 2011|A1F1A0QQP2XVH5|             Mark B|Good functionalit...|    1293840000|\n",
      "|B00000JBLH| [7, 8]|    5.0|I've started doin...|04 19, 2006| A49R5DBXXQDE5|       R. D Johnson|One of the last o...|    1145404800|\n",
      "|B00000JBLH| [0, 0]|    5.0|For simple calcul...| 08 4, 2013|A2XRMQA6PJ5ZJ8|Roger J. Buffington|      Still the best|    1375574400|\n",
      "+----------+-------+-------+--------------------+-----------+--------------+-------------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 53258 rows and 9 columns\n",
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check size and shape of data\n",
    "print(f\"Data has {df.count():d} rows and {len(df.columns):d} columns\")\n",
    "\n",
    "# Check for missing\n",
    "#df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb08c3604e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out overall\n",
    "sentiment_count = df.groupby('overall').count().collect()\n",
    "x = [x[0] for x in sentiment_count]\n",
    "ht = [ct[1] for ct in sentiment_count]\n",
    "\n",
    "plt.bar(x, ht)\n",
    "plt.title('Overall Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try muliclass logistic regression with largely imbalanced classes, then try a binary situation where 4s and 5s equal good and 1-3 are bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              corpus|\n",
      "+--------------------+\n",
      "|A solid performer...|\n",
      "|Price of GOLD is ...|\n",
      "|Good functionalit...|\n",
      "|One of the last o...|\n",
      "|Still the best Fo...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+--------------------+\n",
      "|overall|              corpus|\n",
      "+-------+--------------------+\n",
      "|    5.0|A solid performer...|\n",
      "|    5.0|Price of GOLD is ...|\n",
      "|    2.0|Good functionalit...|\n",
      "|    5.0|One of the last o...|\n",
      "|    5.0|Still the best Fo...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, col, lit\n",
    "\n",
    "# Combine the summary and review text into one column labelled corpus\n",
    "df= df.withColumn('corpus', concat(col(\"summary\"), lit(\" \"), col(\"reviewText\")))\n",
    "target = df.select('overall')\n",
    "df[['corpus']].show(5)\n",
    "\n",
    "# Dataframe of corpus and target\n",
    "data = df.select(\"overall\", \"corpus\")\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try sampling down to see if error is related to memory\n",
    "small_data = data.sample(False,.8, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|overall|            features|\n",
      "+-------+--------------------+\n",
      "|    5.0|(1000,[4,5,36,39,...|\n",
      "|    5.0|(1000,[1,5,6,8,10...|\n",
      "|    2.0|(1000,[18,25,36,5...|\n",
      "|    5.0|(1000,[2,6,8,13,1...|\n",
      "|    5.0|(1000,[7,8,9,32,3...|\n",
      "|    5.0|(1000,[0,1,8,18,2...|\n",
      "|    5.0|(1000,[8,22,25,26...|\n",
      "|    5.0|(1000,[8,18,23,36...|\n",
      "|    5.0|(1000,[1,12,16,19...|\n",
      "|    5.0|(1000,[121,219,24...|\n",
      "|    5.0|(1000,[0,18,36,77...|\n",
      "|    5.0|(1000,[4,18,36,37...|\n",
      "|    5.0|(1000,[44,47,48,4...|\n",
      "|    5.0|(1000,[1,15,36,38...|\n",
      "|    4.0|(1000,[0,1,5,6,12...|\n",
      "|    5.0|(1000,[36,39,105,...|\n",
      "|    5.0|(1000,[4,15,18,28...|\n",
      "|    5.0|(1000,[18,19,36,4...|\n",
      "|    4.0|(1000,[76,82,140,...|\n",
      "|    5.0|(1000,[13,18,48,7...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate, Tokenizer, HashingTF and transform corpus\n",
    "# Tokenize corpus\n",
    "tokenizer = Tokenizer(inputCol=\"corpus\", outputCol=\"tokens\")\n",
    "tokenized_corpus = tokenizer.transform(data)\n",
    "\n",
    "# Get term frequencies of tokens\n",
    "hashingTF = HashingTF(inputCol='tokens', outputCol='raw_tf', numFeatures=1000)\n",
    "tf_data = hashingTF.transform(tokenized_corpus)\n",
    "\n",
    "# Calculate IDF for features\n",
    "idf = IDF(inputCol=\"raw_tf\", outputCol=\"features\")\n",
    "idfModel = idf.fit(tf_data)\n",
    "\n",
    "tfidf_vectors = idfModel.transform(tf_data)\n",
    "\n",
    "tfidf_vectors.select(\"overall\", \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(20,[0,5,9,17],[0...|\n",
      "|  0.0|(20,[2,7,9,13,15]...|\n",
      "|  1.0|(20,[4,6,13,15,18...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example from Apache Spark Documentation\n",
    "\n",
    "sentenceData = sc.createDataFrame([\n",
    "    (0.0, \"Hi I heard about Spark\"),\n",
    "    (0.0, \"I wish Java could use case classes\"),\n",
    "    (1.0, \"Logistic regression models are neat\")\n",
    "], [\"label\", \"sentence\"])\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(sentenceData)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "rescaledData.select(\"label\", \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build the training indexers / split data / logistic regression classifier\n",
    "\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"overall\", outputCol=\"indexedLabel\").fit(tfidf_vectors)\n",
    "\n",
    "# now generate the indexed feature vector\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(tfidf_vectors)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(trainingData, testData) = tfidf_vectors.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a Logistic Regression model.\n",
    "lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipelinelr = Pipeline(stages=[labelIndexer, featureIndexer, lr, labelConverter])\n",
    "pipelinerf = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for Logistic = 0.385253\n",
      "Accuracy for Logistic = 0.614747\n",
      "Test Error for Forest = 0.432244\n",
      "Accuracy for Forest = 0.567756\n"
     ]
    }
   ],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model_lr = pipelinelr.fit(trainingData)\n",
    "model_rf = pipelinerf.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictionslr = model_lr.transform(testData)\n",
    "predictionsrf = model_rf.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy_lr = evaluator.evaluate(predictionslr)\n",
    "accuracy_rf = evaluator.evaluate(predictionsrf)\n",
    "\n",
    "print(f\"Test Error for Logistic = {(1.0 - accuracy_lr):g}\\nAccuracy for Logistic = {accuracy_lr:g}\")\n",
    "print(f\"Test Error for Forest = {(1.0 - accuracy_rf):g}\\nAccuracy for Forest = {accuracy_rf:g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Binary situation where 4s and 5s are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+\n",
      "|overall|              corpus|overall_recode|\n",
      "+-------+--------------------+--------------+\n",
      "|    5.0|A solid performer...|             1|\n",
      "|    5.0|Price of GOLD is ...|             1|\n",
      "|    2.0|Good functionalit...|            -1|\n",
      "|    5.0|One of the last o...|             1|\n",
      "|    5.0|Still the best Fo...|             1|\n",
      "+-------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We need to set up user defined function to map the binary case to our target\n",
    "# We will need to define the datatype when using user defined function\n",
    "\n",
    "# Import udf and integer datatype\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# If value greater than or equal to 4 replace with 1 else replace with -1, datatype = integer\n",
    "udf = UserDefinedFunction(lambda x: 1 if x >= 4.0 else -1, IntegerType())\n",
    "\n",
    "data = data.withColumn(\"overall_recode\",udf(data.overall))\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb05c7c8400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out overall\n",
    "\n",
    "# counts for pos(1) and neg(-1) reviews - returns RDD list\n",
    "overall_count = data.groupby('overall_recode').count().collect()\n",
    "x = [x[0] for x in overall_count]\n",
    "ht = [ct[1] for ct in overall_count]\n",
    "\n",
    "plt.bar(x, ht)\n",
    "plt.title('Overall Recode Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+\n",
      "|overall|overall_recode|            features|\n",
      "+-------+--------------+--------------------+\n",
      "|    5.0|             1|(1000,[4,5,36,39,...|\n",
      "|    5.0|             1|(1000,[1,5,6,8,10...|\n",
      "|    2.0|            -1|(1000,[18,25,36,5...|\n",
      "|    5.0|             1|(1000,[2,6,8,13,1...|\n",
      "|    5.0|             1|(1000,[7,8,9,32,3...|\n",
      "|    5.0|             1|(1000,[0,1,8,18,2...|\n",
      "|    5.0|             1|(1000,[8,22,25,26...|\n",
      "|    5.0|             1|(1000,[8,18,23,36...|\n",
      "|    5.0|             1|(1000,[1,12,16,19...|\n",
      "|    5.0|             1|(1000,[121,219,24...|\n",
      "|    5.0|             1|(1000,[0,18,36,77...|\n",
      "|    5.0|             1|(1000,[4,18,36,37...|\n",
      "|    5.0|             1|(1000,[44,47,48,4...|\n",
      "|    5.0|             1|(1000,[1,15,36,38...|\n",
      "|    4.0|             1|(1000,[0,1,5,6,12...|\n",
      "|    5.0|             1|(1000,[36,39,105,...|\n",
      "|    5.0|             1|(1000,[4,15,18,28...|\n",
      "|    5.0|             1|(1000,[18,19,36,4...|\n",
      "|    4.0|             1|(1000,[76,82,140,...|\n",
      "|    5.0|             1|(1000,[13,18,48,7...|\n",
      "+-------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the training indexers / split data / logistic regression classifier\n",
    "\n",
    "# Instantiate, Tokenizer, HashingTF and transform corpus\n",
    "# Tokenize corpus\n",
    "\n",
    "# Re run tokenizer to add overall_recode to dataframe\n",
    "tokenizer = Tokenizer(inputCol=\"corpus\", outputCol=\"tokens\")\n",
    "tokenized_corpus = tokenizer.transform(data)\n",
    "\n",
    "# Get term frequencies of tokens\n",
    "hashingTF = HashingTF(inputCol='tokens', outputCol='raw_tf', numFeatures=1000)\n",
    "tf_data = hashingTF.transform(tokenized_corpus)\n",
    "\n",
    "# Calculate IDF for features\n",
    "idf = IDF(inputCol=\"raw_tf\", outputCol=\"features\")\n",
    "idfModel = idf.fit(tf_data)\n",
    "\n",
    "tfidf_vectors = idfModel.transform(tf_data)\n",
    "\n",
    "tfidf_vectors.select(\"overall\",'overall_recode', \"features\").show()\n",
    "\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"overall_recode\", outputCol=\"indexedLabel\").fit(tfidf_vectors)\n",
    "\n",
    "# now generate the indexed feature vector\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(tfidf_vectors)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(trainingData, testData) = tfidf_vectors.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a Logistic Regression model.\n",
    "lr = LogisticRegression(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipelinelr = Pipeline(stages=[labelIndexer, featureIndexer, lr, labelConverter])\n",
    "pipelinerf = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for Logistic = 0.142817\n",
      "Accuracy for Logistic = 0.857183\n",
      "Test Error for Forest = 0.150562\n",
      "Accuracy for Forest = 0.849438\n"
     ]
    }
   ],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model_lr = pipelinelr.fit(trainingData)\n",
    "model_rf = pipelinerf.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictionslr = model_lr.transform(testData)\n",
    "predictionsrf = model_rf.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy_lr = evaluator.evaluate(predictionslr)\n",
    "accuracy_rf = evaluator.evaluate(predictionsrf)\n",
    "\n",
    "print(f\"Test Error for Logistic = {(1.0 - accuracy_lr):g}\\nAccuracy for Logistic = {accuracy_lr:g}\")\n",
    "print(f\"Test Error for Forest = {(1.0 - accuracy_rf):g}\\nAccuracy for Forest = {accuracy_rf:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 148, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 409, in dump\n",
      "    self.save(obj)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 751, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 255, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 292, in save_function_tuple\n",
      "    save((code, closure, base_globals))\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 736, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 805, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 255, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 292, in save_function_tuple\n",
      "    save((code, closure, base_globals))\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 736, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 805, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 255, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 292, in save_function_tuple\n",
      "    save((code, closure, base_globals))\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 736, in save_tuple\n",
      "    save(element)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 808, in _batch_appends\n",
      "    save(tmp[0])\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 249, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 297, in save_function_tuple\n",
      "    save(f_globals)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 821, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 852, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 521, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 600, in save_reduce\n",
      "    save(state)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 821, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 805, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 521, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle.py\", line 600, in save_reduce\n",
      "    save(state)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 821, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/usr/local/lib/python3.6/pickle.py\", line 496, in save\n",
      "    rv = reduce(self.proto)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\", line 1133, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/local/spark/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\", line 323, in get_return_value\n",
      "    format(target_id, \".\", name, value))\n",
      "py4j.protocol.Py4JError: An error occurred while calling o405.__getstate__. Trace:\n",
      "py4j.Py4JException: Method __getstate__([]) does not exist\n",
      "\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n",
      "\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:272)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: Py4JError: An error occurred while calling o405.__getstate__. Trace:\npy4j.Py4JException: Method __getstate__([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:272)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_skel_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREDUCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0;31m# Subtle.  Same as in the big comment below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_skel_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREDUCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0;31m# Subtle.  Same as in the big comment below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_skel_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREDUCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m             \u001b[0;31m# Subtle.  Same as in the big comment below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m#print(\"save global\", islambda(obj), obj.__code__.co_filename, modname, themodule)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;31m# save the rest of the func data needed by _fill_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    851\u001b[0m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    846\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                     format(target_id, \".\", name, value))\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o405.__getstate__. Trace:\npy4j.Py4JException: Method __getstate__([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:272)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-20f1da0133a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictionAndLabels_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverall_recode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionAndLabels_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/mllib/evaluation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, scoreAndLabels)\u001b[0m\n\u001b[1;32m     50\u001b[0m         df = sql_ctx.createDataFrame(scoreAndLabels, schema=StructType([\n\u001b[1;32m     51\u001b[0m             \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoubleType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnullable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             StructField(\"label\", DoubleType(), nullable=False)]))\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mjava_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryClassificationMetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/context.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mPy4JJavaError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_to_java_object_rdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2277\u001b[0m         \"\"\"\n\u001b[1;32m   2278\u001b[0m         \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pickled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonToJava\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcountApprox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_jrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2454\u001b[0m         wrapped_func = _wrap_function(self.ctx, self.func, self._prev_jrdd_deserializer,\n\u001b[0;32m-> 2455\u001b[0;31m                                       self._jrdd_deserializer, profiler)\n\u001b[0m\u001b[1;32m   2456\u001b[0m         python_rdd = self.ctx._jvm.PythonRDD(self._prev_jrdd.rdd(), wrapped_func,\n\u001b[1;32m   2457\u001b[0m                                              self.preservesPartitioning)\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[1;32m   2386\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serializer should not be empty\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[1;32m   2390\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   2372\u001b[0m     \u001b[0;31m# the serialized command will be compressed by broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m     \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m     \u001b[0mpickled_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 1M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m         \u001b[0;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m     \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not serialize object: %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mprint_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_memoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not serialize object: Py4JError: An error occurred while calling o405.__getstate__. Trace:\npy4j.Py4JException: Method __getstate__([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:272)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "predictionAndLabels_lr = testData.rdd.map(lambda lp: (float(model_lr.predict(lp.features)), lp.overall_recode))\n",
    "metrics = BinaryClassificationMetrics(predictionAndLabels_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need help with the dataframe to rdd pair (key-value pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Random Forest Classifier with Spark in Batch Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you'll learn the basics of working with Spark in batch mode to build a random forest classifier. Before digging in, make sure to read the background context in the related reading in the curriculum!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Import dependencies\n",
    "\n",
    "First off, we need to import the tools we'll need from PySpark. The imports below allow us to connect to the Spark server, load our data, clean it, and prepare, execute, and evaluate a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set our constants\n",
    "\n",
    "Next, we create a set of constants that we can refer to throughout the notebook. These are values that the rest of our code needs to run, but that we might need to change at some point (for instance, if the location of our data changes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"/home/ds/notebooks/datasets/UCI_HAR/allData.csv\"\n",
    "CSV_ACTIVITY_LABEL_PATH = \"/home/ds/notebooks/datasets/UCI_HAR/activity_labels.csv\"\n",
    "APP_NAME = \"UCI HAR Random Forest Example\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "RANDOM_SEED = 141107\n",
    "TRAINING_DATA_RATIO = 0.8\n",
    "RF_NUM_TREES = 10\n",
    "RF_MAX_DEPTH = 4\n",
    "RF_NUM_BINS = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the server and load data\n",
    "\n",
    "Now we're ready to connect to the Spark server. We do that (relying on the constants set above) and then load our labels (loaded into `activity_labels`) and activity data (loaded into `df`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
    "activity_labels = spark.read.options(inferschema = \"true\").csv(CSV_ACTIVITY_LABEL_PATH)\n",
    "df = spark.read.options(inferschema = \"true\").csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the data\n",
    "\n",
    "If our data has been properly cleaned and prepared, it will meet the following criteria, which we'll verify in just a moment:\n",
    "\n",
    "* The dataframe shape should be 10,299 rows by 562 columns\n",
    "* All feature columns should be doubles. Note than one of the columns is for our label and it will not be double.\n",
    "* There should be no nulls. This point is crucial because Spark will fail to build our vector variables for our classifier if there are any null values.\n",
    "\n",
    "Let's confirm these points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is 10299 rows by 562 columns.\n"
     ]
    }
   ],
   "source": [
    "# Confirm the dataframe shape is 10,299 rows by 562 columns\n",
    "print(f\"Dataset shape is {df.count():d} rows by {len(df.columns):d} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561 columns out of 562 total are type double.\n"
     ]
    }
   ],
   "source": [
    "# Confirm that all feature columns are doubles via a list comprehension\n",
    "# We're expecting 561 of 562 here, accounting for the labels column\n",
    "double_cols = [col[0] for col in df.dtypes if col[1] == 'double']\n",
    "print(f\"{len(double_cols):d} columns out of {len(df.columns):d} total are type double.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Confirm there are no null values. We use the dataframe select method to build a \n",
    "# list that is then converted to a Python dict. This way it's easy to sum up the nulls.\n",
    "null_counts = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n",
    "                         for c in df.columns]).toPandas().to_dict(orient='records')\n",
    "\n",
    "print(f\"There are {sum(null_counts[0].values()):d} null values in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and run our classifier in Spark\n",
    "\n",
    "After confirming our data is clean, we're ready to reshape the data and run the random forest model.\n",
    "\n",
    "In Spark, we manipulate the data to work in a Spark pipeline, define each of the steps in the pipeline, chain them together, and finally run the pipeline.\n",
    "\n",
    "Apache Spark classifiers expect 2 columns of input:\n",
    "\n",
    "1. __labels__: an indexed set of numeric variables that represent the classification from the set of features we provide.\n",
    "2. __features__: an indexed, vector variable that contains all of the feature values in each row. \n",
    "\n",
    "In order to do this, we need to create these 2 columns from our dataset - the data is there, but not yet in a format we can use in the classifier.\n",
    "\n",
    "To create the indexed labels column, we'll create a column called `indexedLabel` using the `StringIndexer` method. We use the column `_c0` as the source for our label index since that contains our labels. The column contains only one value per index.\n",
    "    \n",
    "To create the indexed features column, we'll need to do two things. First, we'll create the vector of features using the `VectorAssembler` method. To create this vector, we'll need to use all 561 numeric columns from our data frame. The vector assembler will create a new column called `features`, and each row of this column will contain a 561-element vector that is built from the 561 features in the dataset.\n",
    "\n",
    "Finally, we'll complete the data preparation by creating an indexed vector from the `features` column. We'll call this vector `indexedFeatures`.\n",
    "    \n",
    "Since the classifier expects indexed labels and an indexed vector column of data, we'll use the `indexedLabel` and `indexedFeatures` as inputs to our random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our feature vector.\n",
    "# Note that we're doing the work on the `df` object - we don't create new dataframes, \n",
    "# just add columns to the one we already are using.\n",
    "\n",
    "# the transform method creates the column.\n",
    "\n",
    "df = VectorAssembler(inputCols=double_cols, outputCol=\"features\").transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that the features are there. It's easy to do this in Apache Spark using the `select` and `show` methods on the dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|_c0|            features|\n",
      "+---+--------------------+\n",
      "|  5|[0.289,-0.0203,-0...|\n",
      "|  5|[0.278,-0.0164,-0...|\n",
      "|  5|[0.28,-0.0195,-0....|\n",
      "|  5|[0.279,-0.0262,-0...|\n",
      "|  5|[0.277,-0.0166,-0...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"_c0\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " '_c1',\n",
       " '_c2',\n",
       " '_c3',\n",
       " '_c4',\n",
       " '_c5',\n",
       " '_c6',\n",
       " '_c7',\n",
       " '_c8',\n",
       " '_c9',\n",
       " '_c10',\n",
       " '_c11',\n",
       " '_c12',\n",
       " '_c13',\n",
       " '_c14',\n",
       " '_c15',\n",
       " '_c16',\n",
       " '_c17',\n",
       " '_c18',\n",
       " '_c19',\n",
       " '_c20',\n",
       " '_c21',\n",
       " '_c22',\n",
       " '_c23',\n",
       " '_c24',\n",
       " '_c25',\n",
       " '_c26',\n",
       " '_c27',\n",
       " '_c28',\n",
       " '_c29',\n",
       " '_c30',\n",
       " '_c31',\n",
       " '_c32',\n",
       " '_c33',\n",
       " '_c34',\n",
       " '_c35',\n",
       " '_c36',\n",
       " '_c37',\n",
       " '_c38',\n",
       " '_c39',\n",
       " '_c40',\n",
       " '_c41',\n",
       " '_c42',\n",
       " '_c43',\n",
       " '_c44',\n",
       " '_c45',\n",
       " '_c46',\n",
       " '_c47',\n",
       " '_c48',\n",
       " '_c49',\n",
       " '_c50',\n",
       " '_c51',\n",
       " '_c52',\n",
       " '_c53',\n",
       " '_c54',\n",
       " '_c55',\n",
       " '_c56',\n",
       " '_c57',\n",
       " '_c58',\n",
       " '_c59',\n",
       " '_c60',\n",
       " '_c61',\n",
       " '_c62',\n",
       " '_c63',\n",
       " '_c64',\n",
       " '_c65',\n",
       " '_c66',\n",
       " '_c67',\n",
       " '_c68',\n",
       " '_c69',\n",
       " '_c70',\n",
       " '_c71',\n",
       " '_c72',\n",
       " '_c73',\n",
       " '_c74',\n",
       " '_c75',\n",
       " '_c76',\n",
       " '_c77',\n",
       " '_c78',\n",
       " '_c79',\n",
       " '_c80',\n",
       " '_c81',\n",
       " '_c82',\n",
       " '_c83',\n",
       " '_c84',\n",
       " '_c85',\n",
       " '_c86',\n",
       " '_c87',\n",
       " '_c88',\n",
       " '_c89',\n",
       " '_c90',\n",
       " '_c91',\n",
       " '_c92',\n",
       " '_c93',\n",
       " '_c94',\n",
       " '_c95',\n",
       " '_c96',\n",
       " '_c97',\n",
       " '_c98',\n",
       " '_c99',\n",
       " '_c100',\n",
       " '_c101',\n",
       " '_c102',\n",
       " '_c103',\n",
       " '_c104',\n",
       " '_c105',\n",
       " '_c106',\n",
       " '_c107',\n",
       " '_c108',\n",
       " '_c109',\n",
       " '_c110',\n",
       " '_c111',\n",
       " '_c112',\n",
       " '_c113',\n",
       " '_c114',\n",
       " '_c115',\n",
       " '_c116',\n",
       " '_c117',\n",
       " '_c118',\n",
       " '_c119',\n",
       " '_c120',\n",
       " '_c121',\n",
       " '_c122',\n",
       " '_c123',\n",
       " '_c124',\n",
       " '_c125',\n",
       " '_c126',\n",
       " '_c127',\n",
       " '_c128',\n",
       " '_c129',\n",
       " '_c130',\n",
       " '_c131',\n",
       " '_c132',\n",
       " '_c133',\n",
       " '_c134',\n",
       " '_c135',\n",
       " '_c136',\n",
       " '_c137',\n",
       " '_c138',\n",
       " '_c139',\n",
       " '_c140',\n",
       " '_c141',\n",
       " '_c142',\n",
       " '_c143',\n",
       " '_c144',\n",
       " '_c145',\n",
       " '_c146',\n",
       " '_c147',\n",
       " '_c148',\n",
       " '_c149',\n",
       " '_c150',\n",
       " '_c151',\n",
       " '_c152',\n",
       " '_c153',\n",
       " '_c154',\n",
       " '_c155',\n",
       " '_c156',\n",
       " '_c157',\n",
       " '_c158',\n",
       " '_c159',\n",
       " '_c160',\n",
       " '_c161',\n",
       " '_c162',\n",
       " '_c163',\n",
       " '_c164',\n",
       " '_c165',\n",
       " '_c166',\n",
       " '_c167',\n",
       " '_c168',\n",
       " '_c169',\n",
       " '_c170',\n",
       " '_c171',\n",
       " '_c172',\n",
       " '_c173',\n",
       " '_c174',\n",
       " '_c175',\n",
       " '_c176',\n",
       " '_c177',\n",
       " '_c178',\n",
       " '_c179',\n",
       " '_c180',\n",
       " '_c181',\n",
       " '_c182',\n",
       " '_c183',\n",
       " '_c184',\n",
       " '_c185',\n",
       " '_c186',\n",
       " '_c187',\n",
       " '_c188',\n",
       " '_c189',\n",
       " '_c190',\n",
       " '_c191',\n",
       " '_c192',\n",
       " '_c193',\n",
       " '_c194',\n",
       " '_c195',\n",
       " '_c196',\n",
       " '_c197',\n",
       " '_c198',\n",
       " '_c199',\n",
       " '_c200',\n",
       " '_c201',\n",
       " '_c202',\n",
       " '_c203',\n",
       " '_c204',\n",
       " '_c205',\n",
       " '_c206',\n",
       " '_c207',\n",
       " '_c208',\n",
       " '_c209',\n",
       " '_c210',\n",
       " '_c211',\n",
       " '_c212',\n",
       " '_c213',\n",
       " '_c214',\n",
       " '_c215',\n",
       " '_c216',\n",
       " '_c217',\n",
       " '_c218',\n",
       " '_c219',\n",
       " '_c220',\n",
       " '_c221',\n",
       " '_c222',\n",
       " '_c223',\n",
       " '_c224',\n",
       " '_c225',\n",
       " '_c226',\n",
       " '_c227',\n",
       " '_c228',\n",
       " '_c229',\n",
       " '_c230',\n",
       " '_c231',\n",
       " '_c232',\n",
       " '_c233',\n",
       " '_c234',\n",
       " '_c235',\n",
       " '_c236',\n",
       " '_c237',\n",
       " '_c238',\n",
       " '_c239',\n",
       " '_c240',\n",
       " '_c241',\n",
       " '_c242',\n",
       " '_c243',\n",
       " '_c244',\n",
       " '_c245',\n",
       " '_c246',\n",
       " '_c247',\n",
       " '_c248',\n",
       " '_c249',\n",
       " '_c250',\n",
       " '_c251',\n",
       " '_c252',\n",
       " '_c253',\n",
       " '_c254',\n",
       " '_c255',\n",
       " '_c256',\n",
       " '_c257',\n",
       " '_c258',\n",
       " '_c259',\n",
       " '_c260',\n",
       " '_c261',\n",
       " '_c262',\n",
       " '_c263',\n",
       " '_c264',\n",
       " '_c265',\n",
       " '_c266',\n",
       " '_c267',\n",
       " '_c268',\n",
       " '_c269',\n",
       " '_c270',\n",
       " '_c271',\n",
       " '_c272',\n",
       " '_c273',\n",
       " '_c274',\n",
       " '_c275',\n",
       " '_c276',\n",
       " '_c277',\n",
       " '_c278',\n",
       " '_c279',\n",
       " '_c280',\n",
       " '_c281',\n",
       " '_c282',\n",
       " '_c283',\n",
       " '_c284',\n",
       " '_c285',\n",
       " '_c286',\n",
       " '_c287',\n",
       " '_c288',\n",
       " '_c289',\n",
       " '_c290',\n",
       " '_c291',\n",
       " '_c292',\n",
       " '_c293',\n",
       " '_c294',\n",
       " '_c295',\n",
       " '_c296',\n",
       " '_c297',\n",
       " '_c298',\n",
       " '_c299',\n",
       " '_c300',\n",
       " '_c301',\n",
       " '_c302',\n",
       " '_c303',\n",
       " '_c304',\n",
       " '_c305',\n",
       " '_c306',\n",
       " '_c307',\n",
       " '_c308',\n",
       " '_c309',\n",
       " '_c310',\n",
       " '_c311',\n",
       " '_c312',\n",
       " '_c313',\n",
       " '_c314',\n",
       " '_c315',\n",
       " '_c316',\n",
       " '_c317',\n",
       " '_c318',\n",
       " '_c319',\n",
       " '_c320',\n",
       " '_c321',\n",
       " '_c322',\n",
       " '_c323',\n",
       " '_c324',\n",
       " '_c325',\n",
       " '_c326',\n",
       " '_c327',\n",
       " '_c328',\n",
       " '_c329',\n",
       " '_c330',\n",
       " '_c331',\n",
       " '_c332',\n",
       " '_c333',\n",
       " '_c334',\n",
       " '_c335',\n",
       " '_c336',\n",
       " '_c337',\n",
       " '_c338',\n",
       " '_c339',\n",
       " '_c340',\n",
       " '_c341',\n",
       " '_c342',\n",
       " '_c343',\n",
       " '_c344',\n",
       " '_c345',\n",
       " '_c346',\n",
       " '_c347',\n",
       " '_c348',\n",
       " '_c349',\n",
       " '_c350',\n",
       " '_c351',\n",
       " '_c352',\n",
       " '_c353',\n",
       " '_c354',\n",
       " '_c355',\n",
       " '_c356',\n",
       " '_c357',\n",
       " '_c358',\n",
       " '_c359',\n",
       " '_c360',\n",
       " '_c361',\n",
       " '_c362',\n",
       " '_c363',\n",
       " '_c364',\n",
       " '_c365',\n",
       " '_c366',\n",
       " '_c367',\n",
       " '_c368',\n",
       " '_c369',\n",
       " '_c370',\n",
       " '_c371',\n",
       " '_c372',\n",
       " '_c373',\n",
       " '_c374',\n",
       " '_c375',\n",
       " '_c376',\n",
       " '_c377',\n",
       " '_c378',\n",
       " '_c379',\n",
       " '_c380',\n",
       " '_c381',\n",
       " '_c382',\n",
       " '_c383',\n",
       " '_c384',\n",
       " '_c385',\n",
       " '_c386',\n",
       " '_c387',\n",
       " '_c388',\n",
       " '_c389',\n",
       " '_c390',\n",
       " '_c391',\n",
       " '_c392',\n",
       " '_c393',\n",
       " '_c394',\n",
       " '_c395',\n",
       " '_c396',\n",
       " '_c397',\n",
       " '_c398',\n",
       " '_c399',\n",
       " '_c400',\n",
       " '_c401',\n",
       " '_c402',\n",
       " '_c403',\n",
       " '_c404',\n",
       " '_c405',\n",
       " '_c406',\n",
       " '_c407',\n",
       " '_c408',\n",
       " '_c409',\n",
       " '_c410',\n",
       " '_c411',\n",
       " '_c412',\n",
       " '_c413',\n",
       " '_c414',\n",
       " '_c415',\n",
       " '_c416',\n",
       " '_c417',\n",
       " '_c418',\n",
       " '_c419',\n",
       " '_c420',\n",
       " '_c421',\n",
       " '_c422',\n",
       " '_c423',\n",
       " '_c424',\n",
       " '_c425',\n",
       " '_c426',\n",
       " '_c427',\n",
       " '_c428',\n",
       " '_c429',\n",
       " '_c430',\n",
       " '_c431',\n",
       " '_c432',\n",
       " '_c433',\n",
       " '_c434',\n",
       " '_c435',\n",
       " '_c436',\n",
       " '_c437',\n",
       " '_c438',\n",
       " '_c439',\n",
       " '_c440',\n",
       " '_c441',\n",
       " '_c442',\n",
       " '_c443',\n",
       " '_c444',\n",
       " '_c445',\n",
       " '_c446',\n",
       " '_c447',\n",
       " '_c448',\n",
       " '_c449',\n",
       " '_c450',\n",
       " '_c451',\n",
       " '_c452',\n",
       " '_c453',\n",
       " '_c454',\n",
       " '_c455',\n",
       " '_c456',\n",
       " '_c457',\n",
       " '_c458',\n",
       " '_c459',\n",
       " '_c460',\n",
       " '_c461',\n",
       " '_c462',\n",
       " '_c463',\n",
       " '_c464',\n",
       " '_c465',\n",
       " '_c466',\n",
       " '_c467',\n",
       " '_c468',\n",
       " '_c469',\n",
       " '_c470',\n",
       " '_c471',\n",
       " '_c472',\n",
       " '_c473',\n",
       " '_c474',\n",
       " '_c475',\n",
       " '_c476',\n",
       " '_c477',\n",
       " '_c478',\n",
       " '_c479',\n",
       " '_c480',\n",
       " '_c481',\n",
       " '_c482',\n",
       " '_c483',\n",
       " '_c484',\n",
       " '_c485',\n",
       " '_c486',\n",
       " '_c487',\n",
       " '_c488',\n",
       " '_c489',\n",
       " '_c490',\n",
       " '_c491',\n",
       " '_c492',\n",
       " '_c493',\n",
       " '_c494',\n",
       " '_c495',\n",
       " '_c496',\n",
       " '_c497',\n",
       " '_c498',\n",
       " '_c499',\n",
       " '_c500',\n",
       " '_c501',\n",
       " '_c502',\n",
       " '_c503',\n",
       " '_c504',\n",
       " '_c505',\n",
       " '_c506',\n",
       " '_c507',\n",
       " '_c508',\n",
       " '_c509',\n",
       " '_c510',\n",
       " '_c511',\n",
       " '_c512',\n",
       " '_c513',\n",
       " '_c514',\n",
       " '_c515',\n",
       " '_c516',\n",
       " '_c517',\n",
       " '_c518',\n",
       " '_c519',\n",
       " '_c520',\n",
       " '_c521',\n",
       " '_c522',\n",
       " '_c523',\n",
       " '_c524',\n",
       " '_c525',\n",
       " '_c526',\n",
       " '_c527',\n",
       " '_c528',\n",
       " '_c529',\n",
       " '_c530',\n",
       " '_c531',\n",
       " '_c532',\n",
       " '_c533',\n",
       " '_c534',\n",
       " '_c535',\n",
       " '_c536',\n",
       " '_c537',\n",
       " '_c538',\n",
       " '_c539',\n",
       " '_c540',\n",
       " '_c541',\n",
       " '_c542',\n",
       " '_c543',\n",
       " '_c544',\n",
       " '_c545',\n",
       " '_c546',\n",
       " '_c547',\n",
       " '_c548',\n",
       " '_c549',\n",
       " '_c550',\n",
       " '_c551',\n",
       " '_c552',\n",
       " '_c553',\n",
       " '_c554',\n",
       " '_c555',\n",
       " '_c556',\n",
       " '_c557',\n",
       " '_c558',\n",
       " '_c559',\n",
       " '_c560',\n",
       " '_c561',\n",
       " 'features']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to build the indexers, split our data for training and testing, define our model, and finally chain everything together into a pipeline.\n",
    "\n",
    "__It's important to note that when we execute this cell, we're not actually running our model. At this point, we're only defining its parameters__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers / split data / classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"_c0\", outputCol=\"indexedLabel\").fit(df)\n",
    "\n",
    "# now generate the indexed feature vector\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(df)\n",
    "    \n",
    "# Split the data into training and validation sets (30% held out for testing)\n",
    "(trainingData, testData) = df.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell runs the pipeline, delivering a trained model at the end of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now easy to test our model and make predictions simply by using the model's `transform` method on the `testData` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Now we can use the MulticlassClassificationEvaluator to test the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.10103\n",
      "Accuracy = 0.89897\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+--------------------+\n",
      "|predictedLabel|_c0|            features|\n",
      "+--------------+---+--------------------+\n",
      "|             1|  1|[0.168,-0.00914,-...|\n",
      "|             1|  1|[0.175,-0.0138,-0...|\n",
      "|             1|  1|[0.181,-0.00228,-...|\n",
      "|             1|  1|[0.182,-0.0262,-0...|\n",
      "|             1|  1|[0.184,-0.0227,-0...|\n",
      "+--------------+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"_c0\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringIndexer_47579353622939374cc0, VectorIndexer_4c9fb613531f0f8f407e, RandomForestClassificationModel (uid=RandomForestClassifier_4462a0b8ed9fd22340f1) with 10 trees, IndexToString_4ca496815288eb00a03b]\n"
     ]
    }
   ],
   "source": [
    "rfModel = model.stages#[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "We've seen how to prepare data and build a classifier in Spark. You might want to play around with this notebook and learn more about how Spark works. Here are some ideas:\n",
    "\n",
    "- Look at the set of labels, and see if there are any features that would make sense to combine. Spark allows you to map values into a new column.\n",
    "- Identify the most important features among the 561 source features (using PCA or something similar), then reduce the feature set and see if the model performs better.\n",
    "- Modify the settings of the random forest to see if the performance improves.\n",
    "- Use Spark's tools to find other techniques to evaluate the performance of your model. See if you can figure out how to generate an ROC plot, find the AUC value, or plot a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ask about what to look for in labels that would indicate anything about combining features|\n",
    "-- poor question - look for feature engineering relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(k=4, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "model = pca.fit(df)\n",
    "df_pca = model.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers / split data / classifier\n",
    "# first we'll generate a labelIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"_c0\", outputCol=\"indexedLabel\").fit(df_pca)\n",
    "\n",
    "# now generate the indexed feature vector\n",
    "featureIndexer = VectorIndexer(inputCol=\"pcaFeatures\", outputCol=\"indexedFeatures\", maxCategories=4).fit(df_pca)\n",
    "    \n",
    "# Split the data into training and validation sets (20% held out for testing)\n",
    "(trainingData, testData) = df_pca.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.247702\n",
      "Accuracy = 0.752298\n"
     ]
    }
   ],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator_pca= MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_pca.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Error = 0.255265\n",
      "F1 = 0.744735\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error with f1 score instead of accuracy\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName='f1') # default\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(f\"Test F1 Error = {(1.0 - f1):g}\")\n",
    "print(f\"F1 = {f1:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/home/ds/notebooks/data/mllib/sample_multiclass_classification_data.txt\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.api.python.PythonRDD.getPartitions(PythonRDD.scala:53)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.api.python.PythonRDD.getPartitions(PythonRDD.scala:53)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2094)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:467)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e7a72a3fb121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load training data in LIBSVM format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadLibSVMFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/mllib/sample_multiclass_classification_data.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Split data into training (60%) and test (40%)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/mllib/util.py\u001b[0m in \u001b[0;36mloadLibSVMFile\u001b[0;34m(sc, path, numFeatures, minPartitions, multiclass)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumFeatures\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mnumFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLabeledPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/home/ds/notebooks/data/mllib/sample_multiclass_classification_data.txt\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.api.python.PythonRDD.getPartitions(PythonRDD.scala:53)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.api.python.PythonRDD.getPartitions(PythonRDD.scala:53)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:250)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2094)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:467)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark import SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName(APP_NAME).setMaster(SPARK_URL)\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "\n",
    "# Load training data in LIBSVM format\n",
    "data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_multiclass_classification_data.txt\")\n",
    "\n",
    "# Split data into training (60%) and test (40%)\n",
    "training, test = data.randomSplit([0.6, 0.4], seed=11)\n",
    "training.cache()\n",
    "\n",
    "# Run training algorithm to build the model\n",
    "model = LogisticRegressionWithLBFGS.train(training, numClasses=3)\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "predictionAndLabels = test.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Overall statistics\n",
    "precision = metrics.precision()\n",
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Summary Stats\")\n",
    "print(\"Precision = %s\" % precision)\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)\n",
    "\n",
    "# Statistics by class\n",
    "labels = data.map(lambda lp: lp.label).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
    "\n",
    "# Weighted stats\n",
    "print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark import SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName(APP_NAME).setMaster(SPARK_URL)\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "\n",
    "# Load training data in LIBSVM format\n",
    "data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_multiclass_classification_data.txt\")\n",
    "\n",
    "# Split data into training (60%) and test (40%)\n",
    "training, test = data.randomSplit([0.6, 0.4], seed=11)\n",
    "training.cache()\n",
    "\n",
    "# Run training algorithm to build the model\n",
    "model = LogisticRegressionWithLBFGS.train(training, numClasses=3)\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "predictionAndLabels = test.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Overall statistics\n",
    "precision = metrics.precision()\n",
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Summary Stats\")\n",
    "print(\"Precision = %s\" % precision)\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)\n",
    "\n",
    "# Statistics by class\n",
    "labels = data.map(lambda lp: lp.label).distinct().collect()\n",
    "for label in sorted(labels):\n",
    "    print(\"Class %s precision = %s\" % (label, metrics.precision(label)))\n",
    "    print(\"Class %s recall = %s\" % (label, metrics.recall(label)))\n",
    "    print(\"Class %s F1 Measure = %s\" % (label, metrics.fMeasure(label, beta=1.0)))\n",
    "\n",
    "# Weighted stats\n",
    "print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "metrics = MulticlassMetrics(predandlab)\n",
    "    \n",
    "# Overall statistics\n",
    "precision = metrics.precision()\n",
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Summary Stats\")\n",
    "print(\"Precision = %s\" % precision)\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
